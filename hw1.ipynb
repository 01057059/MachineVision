{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4WT0Zw4-H34",
        "outputId": "1f21074a-c364-483f-b025-354ce913a577"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Moviepy - Building video Output1.mp4.\n",
            "MoviePy - Writing audio in Output1TEMP_MPY_wvf_snd.mp3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video Output1.mp4\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready Output1.mp4\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from moviepy.editor import VideoFileClip\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Video operations function\n",
        "def process_video(video):\n",
        "    # Resize the resolution of the video become 600 x 500\n",
        "    resize = cv2.resize(video, (600,500))\n",
        "\n",
        "    # Convert the video BGR (Blue-Green-Red) color space to grayscale\n",
        "    gray = cv2.cvtColor(resize, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Convert the video color back to a 3-channel (RGB) image\n",
        "    gray_3d = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "    # Apply Gaussian filter to the video\n",
        "    gaussian = cv2.GaussianBlur(resize, (31,31), 0)\n",
        "\n",
        "    # Convert the video to the HSV color space using tensorflow\n",
        "    vid = tf.convert_to_tensor(resize, dtype=tf.float32) / 250.0\n",
        "    hsv = tf.image.rgb_to_hsv(vid)\n",
        "\n",
        "    # Convert the scaled HSV tensor back to the uint8 data type or else it won't be visible\n",
        "    hsv = tf.cast(hsv * 250, dtype=tf.uint8)\n",
        "    hsv_numpy = hsv.numpy()\n",
        "\n",
        "    # Convert the video to the HSV color space using OpenCV\n",
        "    # hsv_numpy = cv2.cvtColor(resize, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "\n",
        "    # Creates a 5x5 kernel with all elements set to 1\n",
        "    kernel = np.array([[1, 1, 1, 1, 1],\n",
        "                       [1, 1, 1, 1, 1],\n",
        "                       [1, 1, 1, 1, 1],\n",
        "                       [1, 1, 1, 1, 1],\n",
        "                       [1, 1, 1, 1, 1]])\n",
        "\n",
        "    # Normalizes the kernel\n",
        "    kernel = kernel/sum(kernel)\n",
        "\n",
        "    # Apply low-pass filtering to the video\n",
        "    low = cv2.filter2D(resize,-1,kernel)\n",
        "\n",
        "    # Apply high-pass filtering to the video\n",
        "    high = resize - cv2.GaussianBlur(resize, (21, 21), 3)+127\n",
        "\n",
        "    # Apply histogram equalization\n",
        "    equalized = cv2.equalizeHist(cv2.cvtColor(resize, cv2.COLOR_BGR2GRAY))\n",
        "    equalized_3d = cv2.cvtColor(equalized, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "    # Stack videos in a 3x2 grid\n",
        "    row1 = np.hstack((resize, gaussian, hsv_numpy))\n",
        "    row2 = np.hstack((low, high, equalized_3d))\n",
        "    combined = np.vstack((row1, row2))\n",
        "    return combined\n",
        "\n",
        "# Load the video from file\n",
        "clip = VideoFileClip(\"homework_1_test_video.mp4\")\n",
        "\n",
        "# Process the video\n",
        "processed_clip = clip.fl_image(process_video)\n",
        "\n",
        "# Save the video into mp4 format with name \"Output1\"\n",
        "processed_clip.write_videofile(\"Output1.mp4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SiIj7RqPms9_"
      },
      "outputs": [],
      "source": [
        "!pip install --force-reinstall https://github.com/yt-dlp/yt-dlp/archive/master.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gR--9PbEARe8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import urllib\n",
        "import numpy as np\n",
        "import yt_dlp\n",
        "import matplotlib.pyplot as plt\n",
        "from moviepy.editor import VideoClip, VideoFileClip, clips_array\n",
        "\n",
        "# Import Youtube URL\n",
        "youtube_url = \"https://www.youtube.com/watch?v=PHqhEgkGfrs\"\n",
        "data = urllib.parse.urlparse(youtube_url)\n",
        "query = urllib.parse.parse_qs(data.query)\n",
        "ID = query[\"v\"][0]\n",
        "video = 'https://www.youtube.com/watch?v={}'.format(str(ID))\n",
        "\n",
        "ydl_options = {\n",
        "    'format': 'best',\n",
        "}\n",
        "\n",
        "with yt_dlp.YoutubeDL(ydl_options) as ydl:\n",
        "    info = ydl.extract_info(video, download=False)\n",
        "    url = info.get(\"url\", None)\n",
        "\n",
        "capture = cv2.VideoCapture(url)\n",
        "mili = 1000\n",
        "start = 0\n",
        "end = 9\n",
        "total = start + end\n",
        "\n",
        "frames = []\n",
        "\n",
        "while True and capture.get(cv2.CAP_PROP_POS_MSEC)<=total*mili:\n",
        "    ret, image = capture.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Resize the resolution of the video become 600 x 500\n",
        "    resize = cv2.resize(image, (600,500))\n",
        "\n",
        "    # Creates a 5x5 kernel with all elements set to 1\n",
        "    kernel = np.array([[1, 1, 1, 1, 1],\n",
        "                       [1, 1, 1, 1, 1],\n",
        "                       [1, 1, 1, 1, 1],\n",
        "                       [1, 1, 1, 1, 1],\n",
        "                       [1, 1, 1, 1, 1]])\n",
        "\n",
        "    # Normalizes the kernel\n",
        "    kernel = kernel/sum(kernel)\n",
        "\n",
        "    # Apply low-pass filtering to the video\n",
        "    low = cv2.filter2D(resize,-1,kernel)\n",
        "\n",
        "    # Apply high-pass filtering to the video\n",
        "    high = resize - cv2.GaussianBlur(resize, (21, 21), 3)+127\n",
        "\n",
        "    # Apply histogram equalization\n",
        "    equalized = cv2.equalizeHist(cv2.cvtColor(resize, cv2.COLOR_BGR2GRAY))\n",
        "\n",
        "    # Convert the video color back to a 3-channel (RGB) image\n",
        "    equaliz = cv2.cvtColor(equalized, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "    # Stack videos in a 3x2 grid\n",
        "    combined = np.hstack((low, high, equaliz))\n",
        "\n",
        "    frames.append(combined)\n",
        "\n",
        "\n",
        "def process_image(image):\n",
        "    # Resize the resolution of the video become 600 x 500\n",
        "    resize = cv2.resize(image, (600,500))\n",
        "\n",
        "    # Convert the video BGR (Blue-Green-Red) color space to grayscale\n",
        "    gray = cv2.cvtColor(resize, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Convert the video color back to a 3-channel (RGB) image\n",
        "    gray_3d = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "    # Apply Gaussian filter to the video\n",
        "    gaussian = cv2.GaussianBlur(resize, (31,31), 0)\n",
        "\n",
        "    # Convert the video to the HSV color space using tensorflow\n",
        "    vid = tf.convert_to_tensor(resize, dtype=tf.float32) / 250.0\n",
        "    hsv = tf.image.rgb_to_hsv(vid)\n",
        "\n",
        "    # Convert the scaled HSV tensor back to the uint8 data type or else it won't be visible\n",
        "    hsv = tf.cast(hsv * 250, dtype=tf.uint8)\n",
        "    hsv_numpy = hsv.numpy()\n",
        "\n",
        "    combined = np.hstack((resize, gaussian, hsv_numpy))\n",
        "    return combined\n",
        "\n",
        "# Input video\n",
        "video1 = VideoFileClip('homework_1_test_video.mp4').fl_image(process_image)\n",
        "video2 = VideoClip(lambda t: frames[int(t*20)], duration=len(frames)/20.0)\n",
        "\n",
        "# Make sure the videos have the same duration\n",
        "duration = min(video1.duration, video2.duration)\n",
        "clip1 = video1.subclip(0, duration)\n",
        "clip2 = video2.subclip(0, duration)\n",
        "\n",
        "# Merge the videos side by side\n",
        "final_clip = clips_array([[clip1],[clip2]])\n",
        "\n",
        "# Write the result to a file\n",
        "final_clip.write_videofile('YoutubeOutput.mp4', fps = 30)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyttsx3\n",
        "!pip install moviepy\n",
        "!pip install gTTS\n",
        "!pip install yt-dlp\n",
        "!pip install moviepy\n",
        "\n",
        "!apt install imagemagick\n",
        "\n",
        "!apt install libmagick++-dev\n",
        "\n",
        "!cat /etc/ImageMagick-6/policy.xml | sed 's/none/read,write/g'> /etc/ImageMagick-6/policy.xml\n",
        "!pip install espeak-py\n",
        "!wget https://github.com/taveevut/Windows-10-Fonts-Default/raw/master/msjh.ttc"
      ],
      "metadata": {
        "id": "s6uhEuqO8Jvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gtts import gTTS\n",
        "from PIL import ImageFont, ImageDraw, Image\n",
        "from moviepy.editor import *\n",
        "from moviepy.video.tools.segmenting import findObjects\n",
        "from moviepy.video.tools.subtitles import SubtitlesClip\n",
        "import pyttsx3\n",
        "import moviepy.video.fx.all as vfx\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "#Subtitles\n",
        "subtitles = '''\n",
        "幾乎整個影片幾乎完全由人工智慧生成,\n",
        "都是用python程式碼寫的,\n",
        "視頻來源是在左上角視頻,\n",
        "中間頂部的影片使用 GAUSSIAN BLUR 進行過濾,\n",
        "右上角影片使用tensorflow轉換為HSV,\n",
        "在左下角，影片使用 KERNEL 過濾為 Low-Pass Filtering,\n",
        "在底部中間，影片被過濾為 High-Pass Filtering,\n",
        "最後右下角的影片透過 Histogram Equalization 進行了增強.\n",
        "Thank You for Watching!!\n",
        "'''\n",
        "\n",
        "source_video_filename     = \"/content/YoutubeOutput.mp4\"\n",
        "background_music_filename = \"/content/calm-background-for-video-121519.mp3\"\n",
        "target_video_with_subtitle= \"VideoSubtitle.mp4\"\n",
        "\n",
        "lines = [msg for msg in subtitles.split('\\n') if len(msg)>0]\n",
        "speech= []\n",
        "\n",
        "# Text To Speech Loop reading every line in the lines\n",
        "for i,msg in enumerate(lines):\n",
        "    gttsObj = gTTS(text = msg, lang = 'zh-TW', slow =False)\n",
        "    gttsObj.save('/content/voice{:04d}.mp3'.format(i))\n",
        "    speech.append(AudioFileClip('/content/voice{:04d}.mp3'.format(i)))\n",
        "\n",
        "# Calculate the start and end time of each narration\n",
        "duration       = np.array([0]+[s.duration for s in speech])\n",
        "cumduration    = np.cumsum(duration)\n",
        "total_duration = int(cumduration[-1])+4\n",
        "\n",
        "# Generate narration subtitles, using msjh font\n",
        "generator = lambda txt: TextClip(txt, font='/content/msjh.ttc', fontsize = 55, color = 'white')\n",
        "subtitles = SubtitlesClip([((cumduration[i],cumduration[i+1]),s) for i,s in enumerate(lines)], generator)\n",
        "\n",
        "# Adjust the video duration so that the video playback time is longer than the entire narration.\n",
        "clip = VideoFileClip(source_video_filename)\n",
        "clip = clip.fx(vfx.speedx,clip.duration/total_duration)\n",
        "\n",
        "# Generate the final video with subtitles.\n",
        "final_clip = CompositeVideoClip([clip, subtitles.set_pos(('center','bottom'))])\n",
        "\n",
        "# Adding Background music, length is same as video and turn down the volume.\n",
        "bgm = AudioFileClip(background_music_filename)\n",
        "bgaudio = bgm.subclip(bgm.duration-total_duration).volumex(0.2)\n",
        "\n",
        "\n",
        "# Combine the audio of the background music and the Narrative\n",
        "voices = concatenate_audioclips(speech)\n",
        "clip.audio = CompositeAudioClip([bgaudio,voices])\n",
        "final_clip = final_clip.set_audio(clip.audio)\n",
        "\n",
        "# Output\n",
        "final_clip.write_videofile(target_video_with_subtitle)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrAAV2bq8Cim",
        "outputId": "566394e8-3aa6-4e45-a698-e0bb498b0bc8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gtts.lang:'zh-TW' has been deprecated, falling back to 'zh-TW'. This fallback will be removed in a future version.\n",
            "WARNING:gtts.lang:'zh-TW' has been deprecated, falling back to 'zh-TW'. This fallback will be removed in a future version.\n",
            "WARNING:gtts.lang:'zh-TW' has been deprecated, falling back to 'zh-TW'. This fallback will be removed in a future version.\n",
            "WARNING:gtts.lang:'zh-TW' has been deprecated, falling back to 'zh-TW'. This fallback will be removed in a future version.\n",
            "WARNING:gtts.lang:'zh-TW' has been deprecated, falling back to 'zh-TW'. This fallback will be removed in a future version.\n",
            "WARNING:gtts.lang:'zh-TW' has been deprecated, falling back to 'zh-TW'. This fallback will be removed in a future version.\n",
            "WARNING:gtts.lang:'zh-TW' has been deprecated, falling back to 'zh-TW'. This fallback will be removed in a future version.\n",
            "WARNING:gtts.lang:'zh-TW' has been deprecated, falling back to 'zh-TW'. This fallback will be removed in a future version.\n",
            "WARNING:gtts.lang:'zh-TW' has been deprecated, falling back to 'zh-TW'. This fallback will be removed in a future version.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Building video VideoSubtitle.mp4.\n",
            "MoviePy - Writing audio in VideoSubtitleTEMP_MPY_wvf_snd.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video VideoSubtitle.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "t: 100%|█████████▉| 1586/1590 [02:54<00:00,  9.69it/s, now=None]WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/moviepy/video/io/ffmpeg_reader.py:123: UserWarning: Warning: in file /content/YoutubeOutput.mp4, 5400000 bytes wanted but 0 bytes read,at frame 297/298, at time 9.90/9.93 sec. Using the last valid frame instead.\n",
            "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready VideoSubtitle.mp4\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}